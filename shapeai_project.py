# -*- coding: utf-8 -*-
"""shapeai_project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17-uZoi6sgIMUzjTMVXib-3e8fhY558R_
"""

import pandas as pd 
    import numpy as np

"""## **READING DATA USING PANDAS**

We use pandas *read_csv* function to read the csv file in python and pandas *DataFrame* method to convert file into the data frame.
"""

df = pd.DataFrame(pd.read_csv('/content/train (1).csv'))
df.head()

"""## **Description of the attributes of the datasheet**

Pclass:Passenger Class(1 = 1st; 2 = 2nd; 3 = 3rd)

survival:Survival (0 = No, 1 = Yes)

name: Name

sex: Sex

age: Age

sibsp: Number of Siblings/Spouses Aboard

parch: Number of Parents/Childern Aborad

ticket: Ticket Number

fare: Passenger Fare (British pound)

cabin: Cabin

embarked: Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)
"""

df.isnull().sum()

"""Sepratimg out the columns which have more than 35% of the values missing in the datasheet"""

# df.insull().sum() returns a pandas series with columns name as the label index
# and total count of null values in the column as it's value
# And we are storing only those column which have more than 35% of the data missing

drop_col = df.isnull().sum()[df.isnull().sum()>(35/100 * df.shape[0])]
drop_col

"""

> **NOTE**: There is no specific number after which you should drop the column .It's just that we decided that on our own according to what we want.






"""

drop_col.index

df.drop(drop_col.index, axis=1, inplace=True)
df.isnull().sum()

df.fillna(df.mean(), inplace = True)
df.isnull().sum()

"""Because **Embraked** contains string values, we see the details of that column separately from others as strings does not mean and all. """

df['Embarked'].describe()

"""For Embarked attribute, we fill the NULL values with the most frequent value in the column.

"""

df['Embarked'].fillna('S',inplace=True)

df.isnull().sum()             ## NOW ALL THE NULL VALUES HAVE BEEN FILLED

df.corr()

"""**sibsp**: Number of Siblings/Spouses Aboard

**parch**: Number of Parents/Childern Aborad

So we can make a new column family_size by combaining these two columns
"""

df['FamilySize'] = df['SibSp'] + df['Parch']
df.drop(['SibSp', 'Parch'], axis=1, inplace=True)
df.corr()

"""**FamilySize in the ship does not have much correlance with survival rate**

Let's check if we weather the person was alone or not can affect the survival rate
"""

df['Alone'] = [0 if df['FamilySize'][i]>0 else 1 for i in df.index]
df.head()

df.groupby(['Alone'])['Survived'].mean()

"""If  the persom is alone he/she has less chance of surviving

> The reason might be the person who is traveling with his family might be belonging to rich class and might be prioritized over other.


"""

df[['Alone','Fare']].corr()

"""So we can see if the person was not alone, the chance the ticket price is higher."""

df['Sex'] = [0 if df['Sex'][i]=='male' else 1 for i in df.index]     # 1 for female, 0 for male
df.groupby(['Sex'])['Survived'].mean()

"""It shows, female passengers have more chance of surviving than male ones.

It shows women were proritized over men.

"""

df.groupby(['Embarked'])['Survived'].mean()

"""# **CONCLUSION**

*   Passengers who borded the ship at Cherbourg, survived more in proportion then the others.
*   People with high class or rich people have higher survival rate than others. The hierarichy might have been followed while saving the passengers.


*   Passengers travelling with their family have higher survival rate.
*   Female passengers were prioritized over men.
"""